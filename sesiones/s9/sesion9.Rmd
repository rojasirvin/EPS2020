---
title: "Reflexiones sobre el diseño de experimentos"
author: "Irvin Rojas"
institute: "CIDE"
date: "15 de septiembre"
header-includes:
  - \usepackage{tikz}
  - \usetikzlibrary{shapes, shadows,arrows}
output:
  xaringan::moon_reader:
    css: [default, "libs/cide.css", metropolis-fonts, "https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap-grid.min.css", "https://use.fontawesome.com/releases/v5.7.2/css/all.css", "https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css"]
    seal: false
    chakra: "https://remarkjs.com/downloads/remark-latest.min.js"
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      titleSlideClass: ["middle", "center"]
      ratio: "16:9"
      beforeInit: ["https://platform.twitter.com/widgets.js", "libs/cols_macro.js"]
      navigation:
        scroll: false


---
class: title-slide

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.path = "figures/")

library(tidyverse)
library(pacman)
library(janitor)
library(sandwich)
#library(nnet)
#library(mlogit)
library(readr)
library(clubSandwich)
library(modelsummary)
library(estimatr)

p_load(tidyverse, foreign, reshape2, psych, qwraps2, forcats, readxl, 
       broom, lmtest, margins, plm, rdrobust, multiwayvcov,
       wesanderson, sandwich, stargazer,
       readstata13, pscore, optmatch, kdensity, MatchIt, bootstrap, matlib, dplyr)

xfun::pkg_load2(c('base64enc', 'htmltools', 'mime'))
```

```{css, echo = FALSE}
.huge .remark-code { /*Change made here*/
  font-size: 200% !important;
}
.tiny .remark-code { /*Change made here*/
  font-size: 60% !important;
}
```

.title[
# Sesión 9. Reflexiones sobre el diseño de experimentos
]
.subtitle[
## Evaluación de Programas Sociales
]
.author[
### Irvin Rojas <br> [rojasirvin.com](https://www.rojasirvin.com/) <br> [<i class="fab fa-github"></i>](https://github.com/rojasirvin) [<i class="fab fa-twitter"></i>](https://twitter.com/RojasIrvin) [<i class="ai ai-google-scholar"></i>](https://scholar.google.com/citations?user=FUwdSTMAAAAJ&hl=en)
]

.affiliation[
### Centro de Investigación y Docencia Económicas <br> División de Economía
]

---
# Agenda

1. 
---

class: inverse, middle, center

# Sobre el número de rondas en un experimento

---

# Más $T$s en los experimentos

- McKenzie (2012), Beyond Baseline and Follow-up: The Case for More T in Experiments

- $Y_{it}$ variable de resultados de interés

- $m$ rondas de datos pre intervención, etiquetadas como $-(m-1)$ hasta 0

- $r$ rondas de datos post intervención, etiquetadas de 1 a $r$


---

# Diferencia en diferencias

- Un estimador comúnmente usado en evaluación y que estudiaremos con mayor detalle en las siguientes semanas es el estimador de diferencia en diferencias (DID)

- En esencia, este estimador consiste en comparar las **diferencias** pre y post tratamiento entre el grupo de tratamiento y el grupo de control

- Suponiendo solo dos periodos, $PRE$ y $POST$ intervención

  - Primera diferencia: $y_{POST}^T-y_{POST}^C$
  
  - Segunda diferencia: $y_{PRE}^T-y_{PRE}^C$
  
--

- Y entonces, el estimador de DID es: 
$$(y_{POST}^T-y_{POST}^C)-(y_{PRE}^T-y_{PRE}^C)$$




---

# ¿Cómo seleccionar la cantidad de rondas de datos?

- En economía, muchos investigadores no consideran apropiadamente la cantidad de rondas de datos pre y post intervención

- Noten que en los ejemplos estudiados en clase la regla parece ser una línea base y una o dos rondas de seguimiento

- Veremos que un elemento clave a considerar en la selección del número de rondas de datos es la autocorrelación en la variable de interés

--

- Supuestos:

  - $n=n_T=n_C$ es el tamaño de la muestra en cada sección cruzada
  - $\rho$ la autocorrelación en la variable de interés
  - $\sigma^2$ es la varianza en la sección cruzada

---

# Estimadores a comparar

- McKenzie (2012) compara tres estimadores:

  - DID: $\hat{\gamma}_{DID}=(\bar{Y}_{POST}^T-\bar{Y}_{POST}^C)-(\bar{Y}_{PRE}^T-\bar{Y}_{PRE}^C)$
  
  - Diferencias post: $\hat{\gamma}_{POST}=(\bar{Y}_{POST}^T-\bar{Y}_{POST}^C)$
  
  - ANCOVA: $\hat{\gamma}_{ANCOVA}=(\bar{Y}_{POST}^T-\bar{Y}_{POST}^C)-\hat{\theta}(\bar{Y}_{PRE}^T-\bar{Y}_{PRE}^C)$

---

# ANCOVA es más eficiente

- **Resultado 1**

- La varianza del estimador ANCOVA es

$$V(\hat{\gamma}_{ANCOVA})=\frac{2\sigma^2}{n}\left(\frac{1+(r-1)\rho}{r}-\frac{m\rho^2}{1+(m-1)\rho}\right)$$

- Frison and Pocock (1992) muestran que el estimador de ANCOVA tiene una varianza menor que estimador de DID y POST

- Econométricamente, el estimador ANCOVA se obtiene condicionando por el promedio del la variable de interés en las rondas pre intervención en una regresión típica post tratamiento

$$Y_{it}=\sum_{t=1}^r\delta_t+\gamma T_{it}+\theta \hat{Y}_{i,PRE}+\varepsilon_{it}$$
donde $T_{it}$ es igual a 1 si la unidad $i$ recibió el tratamiento en el periodo $t$


---

# Sin autocorrelación, $m$ no importa

- **Resultado 2**

- Cuando $\rho=0$, $V(\hat{\gamma}_{ANCOVA})=\frac{2\sigma^2}{n}$

- El número de rondas pre intervención $m$ no importa para la precisión del estimador

- Solo $r$ determina el poder del estimador

- La intuición es que si no hay autocorrelación, cada ronda de datos es igual a la media más ruido

- Y si el tratamiento efectivamente cambia la media, más rondas post tratamiento nos ayudan a eliminar el ruido

- Más generalmente, con $\rho$ baja, los datos de línea base son poco informativos de los valores post intervención

---

# ¿Cómo asignar entre $r$ y $m$ con $T$ fijo?

- Consideremos el caso en que $T$ es fijo

- Podemos obtener el número óptimo de rondas $r$ y, por tanto, de $m$ minimizando $V(\hat{\gamma}_{ANCOVA})$

$$r^*=\frac{1+\rho(T-1)}{2\rho}$$

--

- Consideremos dos casos

| $\rho$ | $r^*$ | $T=4$ | $T=5$ |
|:---:|:---:|:---:|:---:|
| Alta (0.5) | $\frac{T+1}{2}$ | $r=3$, $m=1$ | $r=3$, $m=2$ |
| Baja (0.25) | $\frac{T+3}{2}$ | $r=4$, $m=0$ | $r=4$, $m=1$ |


---

# ¿Cómo asignar entre $r$ y $m$ con $T$ fijo?

- **Resultado 3**

- Típicamente en economía del desarrollo trabajamos con $\rho\approx 0.3$

- Con ANCOVA, uno escoge menos rondas pre tratamiento entre más baja sea la autocorrelación

- Incluso podría ser óptimo $m=0$



---

# Trade-off entre $n$ y $T$

- **Resultado 4**

- Consideremos que tenemos un presupuesto fijo para realizar $K=2nT$ encuestas

- Cuando $\rho$ es grande, es mejor hacer secciones cruzadas más grandes y menos rondas

- Lo contrario ocurre cuando $\rho$ es pequeña

--

- Consideremos el caso en que fijamos $nT$ y tenemos una sola línea base, $m=1$

- McKenzie (2012) muestra que:

  1. $r^*=int({1/\sqrt{\rho}})$
  1. Cuando $\rho<0.5$ dos encuestas de seguimiento darán más poder que una
  1. Cuando $\rho<1/6$ tres encuestas de seguimiento darán más poder que una o dos


---

# Trade-off entre $n$ y $T$

- La intución es que cuando hay mucha autocorrelación, es mejor obtener información de más individuos diferentes pues, cada ronda adicional nos dice poco nuevo de un mismo $i$

- En evaluación, muchas veces $m=r=1$, pero posiblemente hubiera sido mejor sacrificar el tamaño de la sección cruzada en cada ronda y hacer más de un seguimiento

- $r=m=1$ es la elección óptima solo en casos particulares


---

# Trade-off entre $n$ y $T$

- Podemos pensar el problema como uno de asignación de recursos

- Supongamos
  - $a$: costo de inclur un individuo más en una sección cruzada (costo de la intervención)
  - $b$ costo fijo de una ronda adicional
  - $c$ costo marginal de un cuestionario
  - $D$ presupuesto de una línea base
  
--

- Debemos escoger $r$ y $n$ para minimizar:

$$
\begin{aligned}
&\min_{r,n}\frac{2\sigma^2}{n}\left(\frac{1+(r-1)\rho}{r}-\frac{m\rho^2}{1+(m-1)\rho}\right)\\
\\
&s.a\quad 2n(a+c(r+1))+br=D
\end{aligned}
$$
---

# Trade-off entre $n$ y $T$

- Consideremos los siguientes parámetros:

  - $\rho=0.30$
  
  - $b=100$
  
  - $c=50$
  
  - $D=500000$
  
- Caso 1: $a=100$, tratamiento barato

  - En este caso, $n^*=811$ y $r^*=3$

--

- Caso 2: $a=10000$, tratamiento caro

  - $n^*=22$ y $r^*=25$

---

# [Recomendaciones prácticas de McKenzie](https://blogs.worldbank.org/impactevaluations/another-reason-prefer-ancova-dealing-changes-measurement-between-baseline-and-follow)

1. ANCOVA puede ser más poder que DID y las comparaciones post intervención cuando $\rho$ es baja

1. También puede ser útil cuando hay cambios en la forma en que se mide $y$ entre la línea base y los seguimientos

  - Hacer $y_0=0$ para las observaciones que en la línea base están faltantes
  - Crear una dummy $mbl_i=1$ si no hay respuesta en la lína base
  - Estimar $y_i=\alpha+\beta T_i+\gamma Y_{0i} + \pi mbl_i + \varepsilon_i$

--

1. ANCOVA puede servir cuando hay cambios en el fraseo de preguntas (semanal vs mensual, por ejemplo)

  - Supongamos que en la línea base se preguntó por el ingreso mensual, pero en el seguimiento por el ingreso semanal
  - Simplemente estimemos $semanal_i=\alpha+\beta T_i + \gamma mensual_{0i} + \varepsilon_i$

--

1. Puede ayudarnos si cambian los componentes de varibles para formar índices

  - Ponemos el índice de la línea base como control


---

class: inverse, middle, center

# Hipótesis múltiples

---

# Hipótesis múltiples

- **Error tipo I**: concluir que hay un efecto de tratamiento cuando la $H_0$ es verdader, es decir, cuando $H_0:\;\beta_i=0$

- En una investigación fijamos $\alpha$, la probabilidad de rechazar $H_0$ cuando $H_0$ es cierto

- En economía trabajamos con $\alpha=0.5$ o $\alpha=0.01$

- El problema con probar múltiples hipótesis es que inflamos la tasa de error tipo I

--

- Por ejemplo, si tenemos 100 hipótesis y si usamos un valor estándar de $\alpha=0.05$, esperaríamos rechazar 5 hipótesis *por suerte*


---

# Hipótesis múltiples

- Si realizamos una prueba, la probabilidad de cometer un error es $alpha$ y la de no cometer un error es $1-\alpha$

- Si realizamos $n$ pruebas, la probabilidad de no cometer un error es $(1-\alpha)^n$ y la probabilidad de cometer al menos un error es $1-(1-\alpha)^n$

--

- Es decir, la probabilidad de cometer al menos un error se incrementa exponencialmente

--

- Dos estrategias que abordaremos son:

  - Controlar o ajustar $\alpha$
  
  - Crear índices que agreguen varias variables
  
---

class: inverse, middle, center

# Control del error tipo I

---

# Control del error tipo I

- Popper (1995), Multiple Hypothesis Testing

- Definimos *familias* de variables

- Haremos el ajuste *hacia adentro* de estas familias

- Antes habíamos estudiado de Banerjee et al. (2015)

  - Seguridad alimentaria
  - Consumo
  - Activos
  - Salud mental
  
- Dentro de cada familia tenemos $n$ hipótesis $H_i$, con un valor $p$ asociado $p_i$

- Recordemos que $p_i$ es la probabilidad de que el estadístico $T_i$ exceda el valor teórico $t_i$

- Ordenamos las hipótesis de menor a mayor,con $p_1$ siendo el valor más pequeño: $p_1\leq p_2\ldots \leq p_n$


---

# Método de Bonferroni

- El método propuesto por Bonferroni controla la **tasa de error por familia** (FEWR por *family-wise error rate*) definida como la probabilidad de cometer al menos un error tipo I

--

- Consiste en rechazar $H_i$ si $p_i\leq \alpha_i$, donde $\alpha_i$ se escoge de forma que $\sum_i\alpha_i=\alpha$

- Usualmente se hace $\alpha_i=\frac{\alpha}{n}$

--

- Por ejemplo, con dos tests y $\alpha=0.5$, $\alpha_i^B=0.025$

--

- Noten que esta corrección es bastante conservadora

- También podemos ver este test como crear unos valores $p^B$ ajustados: $p_i^B=p_i\times n$

---

# Método de Hochberg

- Si $p_j\leq \frac{\alpha}{n-j+1}$ para todo $j=1,\ldots,n$, rechazar todas las hipótesis $H_i$ para $i<j$

- Visto de otro modo

  - Rechazar todas las $H_i$ si $p_n\leq \alpha$
  
  - Si no, pasar a la hipótesis $n-1$. Rechazar las hipótesis $H_1,\ldots,H_{n-1}$ si $p_{n-1}\leq \frac{\alpha}{2}$
  
  - Continuar hasta encontrar la hipótesis $j$ tal que se rechacen las hipótesis $H_1,\ldots,H_{j}$

---

# ¿Por qué preocuparnos por la FWER?

- La idea de la FWER tiene sentido si nos preocupa tener incluso un solo falso positivo

- En la práctica, podemos vivir con algunos falsos positivos

---

# Método de Benjamini y Hochberg

- Este método controla la tasa de falso descubrimiento

- Si $V$ es el número de falsos rechazos (cuando rechazamos la $H_0$ que es verdadera) y si $R$ es el número total de rechazos, entonces $Q=V/R$ es la proporción de falsos rechazos

- Al valor esperado de $Q$ se le conoce como **tasa de falsos rechazos** (FDR por *false discovery rate*)

--

- Sea $k$ el más grande de los $i$ tal que
$$p_i\leq\frac{1}{n}\alpha$$
entonces rechar todos los $H_i$ para $i=1,2,\ldots,k$

- En la práctica usamos R


---

# Ejemplo: Benjamini & Hochberg (1995)

.pull-left[
```{r echo=T, include=T, eval=T, message=F, warning=F}

data.pvalues<-read_csv("./data_benjamini_hochberg.csv",
                       locale = locale(encoding = "latin1"))  
n <- 15
alpha <- 0.05
```
]

.pull-right[
```{r echo=T, include=T, eval=T, message=F, warning=F}
data.pvalues
```
]


---

# Ejemplo: Bonferroni

.pull-left[
```{r echo=T, include=T, eval=T, message=F, warning=F}
#Bonferroni
data.bonferroni <- data.pvalues %>% 
  mutate(bonferroni_alpha=alpha/n) %>% 
  mutate(bonferrini_rechazar=ifelse(poriginal<=bonferroni_alpha,1,0))
```
]

.tiny[
.pull-right[
```{r echo=T, include=T, eval=T, message=F, warning=F}
data.bonferroni
```
]
]


---

# Ejemplo: Hochberg

.pull-left[
```{r echo=T, include=T, eval=T, message=F, warning=F}
#Hochberg
data.hochberg <- data.pvalues %>% 
  mutate(hochberg_alpha=alpha/(n-hipotesis+1)) %>% 
  mutate(hochberg_rechazar=ifelse(poriginal<=hochberg_alpha,1,0))
```
]

.tiny[
.pull-right[
```{r echo=T, include=T, eval=T, message=F, warning=F}
data.hochberg
```
]
]

---

# Ejemplo: Benjamini & Hochberg

.pull-left[
```{r echo=T, include=T, eval=T, message=F, warning=F}
#Benjamini & Hochberg
data.bh <- data.pvalues %>% 
  mutate(bh_alpha=alpha*hipotesis/n) %>% 
  mutate(bh_rechazar=ifelse(poriginal<=bh_alpha,1,0))
```
]

.tiny[
.pull-right[
```{r echo=T, include=T, eval=T, message=F, warning=F}
data.bh
```
]
]

---

class: inverse, middle, center

# Índices

---

# Creación de $z$-scores

- Otra forma comúnmente usada de evitar el problema de las múltiples hipótesis es crear índices

- Kling, Liebmand y Katz (2007) proponen el siguiente promedio de los $z$-score para generar un solo índice

  1. Definir las familias y las variables que componen cada familia, donde $y_{ij}$ es la $j$ésima variable en la familia con $J$ variables
  
  1. Definir las varibles $y_{ij}$ de tal forma que mayores valores se interpreten como *mejora*
  
  1. Crear $z_{ij}$ como $z_{ij}=\frac{y_{ij}-\bar{y_j}^C}{sd(y_j)^C}\sim(0,1)$, es decir, estandarizar cada una de las $J$ variables usando al grupo de control como referencia
  
  1. Crear $z_i$, un solo índice para cada individuo que agregue los $J$ índices creados antes

- El procedimiento descrito en Banerjee et al. (2015) es bastante general, pues incluye el caso donde hay varias rondas de seguimiento y varios países
  
---

# Creación de $z$-scores

- Podemos escribir el índice descrito como

  $$z_i=\frac{(\frac{1}{J}\sum_j z_{ij})-\bar{z}_j^C}{sd(z_j^C)}$$

- Esta transformación tiene la ventaja de que en la siguiente regresión de efecto de tratamiento

$$z_i=\alpha+\beta T_i + X_i'\gamma+\varepsilon_i$$

el coeficiente $\beta$ se interpreta como el efecto del tratamiento medido en desviaciones estándar con respecto a la media del grupo de control

--

- Noten que todos las variables dentro de la familia *pesan* igual

- Quizás nos gustaría tomar en cuenta la correlación entre las variables dentro del índice

---

# Índice de Anderson

- Anderson (2008) propone el siguiente índice, que puede verse como una generalización del de Kling:

$$\bar{s}_i=\frac{1}{W_{i}}\sum_{j\in J} w_j z_{ij}$$
- $w_j$ es el peso para la variable $j$ y $W_i=\sum_{j\in J}w_{j}$

- Los pesos son una función de la matriz de covarianzas entre las variables que conforman la familia

---

# Próxima sesión

- Continuaré con para afinar la estimación, ahora hablando sobre errores estándar y formas alternativas de hacer inferencia 

  - MHE, Capítulo 8
  - Ho, D. E., & Imai, K. (2006). Randomization inference with natural experiments: An analysis of ballot effects in the 2003 California recall election. *Journal of the American Statistical Association*, 101(475), 888-900.
  
- Discutiremos cómo lo que hemos visto está implementado en una aplicación reciente

  - Rojas Valdes, R.I., Wydick, B., & Lybbert, T.J. (2020). Can Hope Elevate Microfinance? Evidence from Oaxaca, Mexico. Forthcoming in *Oxford Economic Papers*.

---

class: center, middle

Presentación creada usando el paquete [**xaringan**](https://github.com/yihui/xaringan) en R.

El *chakra* viene de [remark.js](https://remarkjs.com), [**knitr**](http://yihui.org/knitr), y [R Markdown](https://rmarkdown.rstudio.com).

Material de clase en versión preliminar.

**No reproducir, no distribuir, no citar.**


