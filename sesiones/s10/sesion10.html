<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Reflexiones sobre el diseño de experimentos</title>
    <meta charset="utf-8" />
    <meta name="author" content="Irvin Rojas" />
    <script src="libs/header-attrs-2.3/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/metropolis-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="libs\cide.css" type="text/css" />
    <link rel="stylesheet" href="https:\\stackpath.bootstrapcdn.com\bootstrap\4.3.1\css\bootstrap-grid.min.css" type="text/css" />
    <link rel="stylesheet" href="https:\\use.fontawesome.com\releases\v5.7.2\css\all.css" type="text/css" />
    <link rel="stylesheet" href="https:\\cdn.rawgit.com\jpswalsh\academicons\master\css\academicons.min.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">

class: title-slide



&lt;style type="text/css"&gt;
.huge .remark-code { /*Change made here*/
  font-size: 200% !important;
}
.tiny .remark-code { /*Change made here*/
  font-size: 60% !important;
}
&lt;/style&gt;

.title[
# Sesión 10. Reflexiones sobre el diseño de experimentos
]
.subtitle[
## Evaluación de Programas Sociales
]
.author[
### Irvin Rojas &lt;br&gt; [rojasirvin.com](https://www.rojasirvin.com/) &lt;br&gt; [&lt;i class="fab fa-github"&gt;&lt;/i&gt;](https://github.com/rojasirvin) [&lt;i class="fab fa-twitter"&gt;&lt;/i&gt;](https://twitter.com/RojasIrvin) [&lt;i class="ai ai-google-scholar"&gt;&lt;/i&gt;](https://scholar.google.com/citations?user=FUwdSTMAAAAJ&amp;hl=en)
]

.affiliation[
### Centro de Investigación y Docencia Económicas &lt;br&gt; División de Economía
]

---
# Agenda

1. Discutir sobre la decisión del número de rondas de datos en un experimento

1. Discutir sobre la definición de las variables dependientes para evitar el problema de las múltiples hipótesis

---

class: inverse, middle, center

# Sobre el número de rondas en un experimento

---

# Más `\(T\)`s en los experimentos

- McKenzie (2012), Beyond Baseline and Follow-up: The Case for More T in Experiments

- `\(Y_{it}\)` variable de resultados de interés

- `\(m\)` rondas de datos pre intervención, etiquetadas como `\(-(m-1)\)` hasta 0

- `\(r\)` rondas de datos post intervención, etiquetadas de 1 a `\(r\)`


---

# Diferencia en diferencias

- Un estimador comúnmente usado en evaluación y que estudiaremos con mayor detalle en las siguientes semanas es el estimador de diferencia en diferencias (DID)

- En esencia, este estimador consiste en comparar las **diferencias** pre y post tratamiento entre el grupo de tratamiento y el grupo de control

- Suponiendo solo dos periodos, `\(PRE\)` y `\(POST\)` intervención

  - Primera diferencia: `\(y_{POST}^T-y_{POST}^C\)`
  
  - Segunda diferencia: `\(y_{PRE}^T-y_{PRE}^C\)`
  
--

- Y entonces, el estimador de DID es: 
`$$(y_{POST}^T-y_{POST}^C)-(y_{PRE}^T-y_{PRE}^C)$$`




---

# ¿Cómo seleccionar la cantidad de rondas de datos?

- En economía, muchos investigadores no consideran apropiadamente la cantidad de rondas de datos pre y post intervención

- Noten que en los ejemplos estudiados en clase la regla parece ser una línea base y una o dos rondas de seguimiento

- Veremos que un elemento clave a considerar en la selección del número de rondas de datos es la autocorrelación en la variable de interés

--

- Supuestos:

  - `\(n=n_T=n_C\)` es el tamaño de la muestra en cada sección cruzada
  - `\(\rho\)` la autocorrelación en la variable de interés
  - `\(\sigma^2\)` es la varianza en la sección cruzada

---

# Estimadores a comparar

- McKenzie (2012) compara tres estimadores:

  - DID: `\(\hat{\gamma}_{DID}=(\bar{Y}_{POST}^T-\bar{Y}_{POST}^C)-(\bar{Y}_{PRE}^T-\bar{Y}_{PRE}^C)\)`
  
  - Diferencias post: `\(\hat{\gamma}_{POST}=(\bar{Y}_{POST}^T-\bar{Y}_{POST}^C)\)`
  
  - ANCOVA: `\(\hat{\gamma}_{ANCOVA}=(\bar{Y}_{POST}^T-\bar{Y}_{POST}^C)-\hat{\theta}(\bar{Y}_{PRE}^T-\bar{Y}_{PRE}^C)\)`

---

# ANCOVA es más eficiente

- **Resultado 1**

- La varianza del estimador ANCOVA es

`$$V(\hat{\gamma}_{ANCOVA})=\frac{2\sigma^2}{n}\left(\frac{1+(r-1)\rho}{r}-\frac{m\rho^2}{1+(m-1)\rho}\right)$$`

- Frison and Pocock (1992) muestran que el estimador de ANCOVA tiene una varianza menor que estimador de DID y POST

- Econométricamente, el estimador ANCOVA se obtiene condicionando por el promedio del la variable de interés en las rondas pre intervención en una regresión típica post tratamiento

`$$Y_{it}=\sum_{t=1}^r\delta_t+\gamma T_{it}+\theta \hat{Y}_{i,PRE}+\varepsilon_{it}$$`
donde `\(T_{it}\)` es igual a 1 si la unidad `\(i\)` recibió el tratamiento en el periodo `\(t\)`


---

# Sin autocorrelación, `\(m\)` no importa

- **Resultado 2**

- Cuando `\(\rho=0\)`, `\(V(\hat{\gamma}_{ANCOVA})=\frac{2\sigma^2}{n}\)`

- El número de rondas pre intervención `\(m\)` no importa para la precisión del estimador

- Solo `\(r\)` determina el poder del estimador

- La intuición es que si no hay autocorrelación, cada ronda de datos es igual a la media más ruido

- Y si el tratamiento efectivamente cambia la media, más rondas post tratamiento nos ayudan a eliminar el ruido

- Más generalmente, con `\(\rho\)` baja, los datos de línea base son poco informativos de los valores post intervención

---

# ¿Cómo asignar entre `\(r\)` y `\(m\)` con `\(T\)` fijo?

- Consideremos el caso en que `\(T\)` es fijo

- Podemos obtener el número óptimo de rondas `\(r\)` y, por tanto, de `\(m\)` minimizando `\(V(\hat{\gamma}_{ANCOVA})\)`

`$$r^*=\frac{1+\rho(T-1)}{2\rho}$$`

--

- Consideremos dos casos

| `\(\rho\)` | `\(r^*\)` | `\(T=4\)` | `\(T=5\)` |
|:---:|:---:|:---:|:---:|
| Alta (0.5) | `\(\frac{T+1}{2}\)` | `\(r=3\)`, `\(m=1\)` | `\(r=3\)`, `\(m=2\)` |
| Baja (0.25) | `\(\frac{T+3}{2}\)` | `\(r=4\)`, `\(m=0\)` | `\(r=4\)`, `\(m=1\)` |


---

# ¿Cómo asignar entre `\(r\)` y `\(m\)` con `\(T\)` fijo?

- **Resultado 3**

- Típicamente en economía del desarrollo trabajamos con `\(\rho\approx 0.3\)`

- Con ANCOVA, uno escoge menos rondas pre tratamiento entre más baja sea la autocorrelación

- Incluso podría ser óptimo `\(m=0\)`



---

# Trade-off entre `\(n\)` y `\(T\)`

- **Resultado 4**

- Consideremos que tenemos un presupuesto fijo para realizar `\(K=2nT\)` encuestas

- Cuando `\(\rho\)` es grande, es mejor hacer secciones cruzadas más grandes y menos rondas

- Lo contrario ocurre cuando `\(\rho\)` es pequeña

--

- Consideremos el caso en que fijamos `\(nT\)` y tenemos una sola línea base, `\(m=1\)`

- McKenzie (2012) muestra que:

  1. `\(r^*=int({1/\sqrt{\rho}})\)`
  1. Cuando `\(\rho&lt;0.5\)` dos encuestas de seguimiento darán más poder que una
  1. Cuando `\(\rho&lt;1/6\)` tres encuestas de seguimiento darán más poder que una o dos


---

# Trade-off entre `\(n\)` y `\(T\)`

- La intución es que cuando hay mucha autocorrelación, es mejor obtener información de más individuos diferentes pues, cada ronda adicional nos dice poco nuevo de un mismo `\(i\)`

- En evaluación, muchas veces `\(m=r=1\)`, pero posiblemente hubiera sido mejor sacrificar el tamaño de la sección cruzada en cada ronda y hacer más de un seguimiento

- `\(r=m=1\)` es la elección óptima solo en casos particulares


---

# Trade-off entre `\(n\)` y `\(T\)`

- Podemos pensar el problema como uno de asignación de recursos

- Supongamos
  - `\(a\)`: costo de incluir un individuo más en una sección cruzada (costo de la intervención)
  - `\(b\)` costo fijo de una ronda adicional
  - `\(c\)` costo marginal de un cuestionario
  - `\(D\)` presupuesto de una línea base
  
--

- Debemos escoger `\(r\)` y `\(n\)` para minimizar:

$$
`\begin{aligned}
&amp;\min_{r,n}\frac{2\sigma^2}{n}\left(\frac{1+(r-1)\rho}{r}-\frac{m\rho^2}{1+(m-1)\rho}\right)\\
\\
&amp;s.a\quad 2n(a+c(r+1))+br=D
\end{aligned}`
$$
---

# Trade-off entre `\(n\)` y `\(T\)`

- Consideremos los siguientes parámetros:

  - `\(\rho=0.30\)`
  
  - `\(b=100\)`
  
  - `\(c=50\)`
  
  - `\(D=500000\)`
  
- Caso 1: `\(a=100\)`, tratamiento barato

  - En este caso, `\(n^*=811\)` y `\(r^*=3\)`

--

- Caso 2: `\(a=10000\)`, tratamiento caro

  - `\(n^*=22\)` y `\(r^*=25\)`

---

# [Recomendaciones prácticas de McKenzie](https://blogs.worldbank.org/impactevaluations/another-reason-prefer-ancova-dealing-changes-measurement-between-baseline-and-follow)

1. ANCOVA puede ser más poder que DID y las comparaciones post intervención cuando `\(\rho\)` es baja

1. También puede ser útil cuando hay cambios en la forma en que se mide `\(y\)` entre la línea base y los seguimientos

  - Hacer `\(y_0=0\)` para las observaciones que en la línea base están faltantes
  - Crear una dummy `\(mbl_i=1\)` si no hay respuesta en la lína base
  - Estimar `\(y_i=\alpha+\beta T_i+\gamma Y_{0i} + \pi mbl_i + \varepsilon_i\)`

--

1. ANCOVA puede servir cuando hay cambios en el fraseo de preguntas (semanal vs mensual, por ejemplo)

  - Supongamos que en la línea base se preguntó por el ingreso mensual, pero en el seguimiento por el ingreso semanal
  - Simplemente estimemos `\(semanal_i=\alpha+\beta T_i + \gamma mensual_{0i} + \varepsilon_i\)`

--

1. Puede ayudarnos si cambian los componentes de varibles para formar índices

  - Ponemos el índice de la línea base como control


---

class: inverse, middle, center

# Hipótesis múltiples

---

# Hipótesis múltiples

- **Error tipo I**: concluir que hay un efecto de tratamiento cuando la `\(H_0\)` es verdader, es decir, cuando `\(H_0:\;\beta_i=0\)`

- En una investigación fijamos `\(\alpha\)`, la probabilidad de rechazar `\(H_0\)` cuando `\(H_0\)` es cierto

- En economía trabajamos con `\(\alpha=0.5\)` o `\(\alpha=0.01\)`

- El problema con probar múltiples hipótesis es que inflamos la tasa de error tipo I

--

- Por ejemplo, si tenemos 100 hipótesis y si usamos un valor estándar de `\(\alpha=0.05\)`, esperaríamos rechazar 5 hipótesis *por suerte*


---

# Hipótesis múltiples

- Si realizamos una prueba, la probabilidad de cometer un error es `\(alpha\)` y la de no cometer un error es `\(1-\alpha\)`

- Si realizamos `\(n\)` pruebas, la probabilidad de no cometer un error es `\((1-\alpha)^n\)` y la probabilidad de cometer al menos un error es `\(1-(1-\alpha)^n\)`

--

- Es decir, la probabilidad de cometer al menos un error se incrementa exponencialmente

--

- Dos estrategias que abordaremos son:

  - Controlar o ajustar `\(\alpha\)`
  
  - Crear índices que agreguen varias variables
  
---

class: inverse, middle, center

# Control del error tipo I

---

# Control del error tipo I

- Popper (1995), Multiple Hypothesis Testing

- Definimos *familias* de variables

- Haremos el ajuste *hacia adentro* de estas familias

- Antes habíamos estudiado de Banerjee et al. (2015)

  - Seguridad alimentaria
  - Consumo
  - Activos
  - Salud mental
  
- Dentro de cada familia tenemos `\(n\)` hipótesis `\(H_i\)`, con un valor `\(p\)` asociado `\(p_i\)`

- Recordemos que `\(p_i\)` es la probabilidad de que el estadístico `\(T_i\)` exceda el valor teórico `\(t_i\)`

- Ordenamos las hipótesis de menor a mayor,con `\(p_1\)` siendo el valor más pequeño: `\(p_1\leq p_2\ldots \leq p_n\)`


---

# Método de Bonferroni

- El método propuesto por Bonferroni controla la **tasa de error por familia** (FEWR por *family-wise error rate*) definida como la probabilidad de cometer al menos un error tipo I

--

- Consiste en rechazar `\(H_i\)` si `\(p_i\leq \alpha_i\)`, donde `\(\alpha_i\)` se escoge de forma que `\(\sum_i\alpha_i=\alpha\)`

- Usualmente se hace `\(\alpha_i=\frac{\alpha}{n}\)`

--

- Por ejemplo, con dos tests y `\(\alpha=0.5\)`, `\(\alpha_i^B=0.025\)`

--

- Noten que esta corrección es bastante conservadora

- También podemos ver este test como crear unos valores `\(p^B\)` ajustados: `\(p_i^B=p_i\times n\)`

---

# Método de Hochberg

- Si `\(p_j\leq \frac{\alpha}{n-j+1}\)` para todo `\(j=1,\ldots,n\)`, rechazar todas las hipótesis `\(H_i\)` para `\(i&lt;j\)`

- Visto de otro modo

  - Rechazar todas las `\(H_i\)` si `\(p_n\leq \alpha\)`
  
  - Si no, pasar a la hipótesis `\(n-1\)`. Rechazar las hipótesis `\(H_1,\ldots,H_{n-1}\)` si `\(p_{n-1}\leq \frac{\alpha}{2}\)`
  
  - Continuar hasta encontrar la hipótesis `\(j\)` tal que se rechacen las hipótesis `\(H_1,\ldots,H_{j}\)`

---

# ¿Por qué preocuparnos por la FWER?

- La idea de la FWER tiene sentido si nos preocupa tener incluso un solo falso positivo

- En la práctica, podemos vivir con algunos falsos positivos

---

# Método de Benjamini y Hochberg

- Este método controla la tasa de falso descubrimiento

- Si `\(V\)` es el número de falsos rechazos (cuando rechazamos la `\(H_0\)` que es verdadera) y si `\(R\)` es el número total de rechazos, entonces `\(Q=V/R\)` es la proporción de falsos rechazos

- Al valor esperado de `\(Q\)` se le conoce como **tasa de falsos rechazos** (FDR por *false discovery rate*)

--

- Sea `\(k\)` el más grande de los `\(i\)` tal que
`$$p_i\leq\frac{1}{n}\alpha$$`
entonces rechar todos los `\(H_i\)` para `\(i=1,2,\ldots,k\)`

- En la práctica usamos R


---

# Ejemplo: Benjamini &amp; Hochberg (1995)

.pull-left[

```r
data.pvalues&lt;-read_csv("./data_benjamini_hochberg.csv",
                       locale = locale(encoding = "latin1"))  
n &lt;- 15
alpha &lt;- 0.05
```
]

.pull-right[

```r
data.pvalues
```

```
## # A tibble: 15 x 2
##    poriginal hipotesis
##        &lt;dbl&gt;     &lt;dbl&gt;
##  1    0.0001         1
##  2    0.0004         2
##  3    0.0019         3
##  4    0.0095         4
##  5    0.0201         5
##  6    0.0278         6
##  7    0.0298         7
##  8    0.0344         8
##  9    0.0459         9
## 10    0.324         10
## 11    0.426         11
## 12    0.572         12
## 13    0.653         13
## 14    0.759         14
## 15    1             15
```
]


---

# Ejemplo: Bonferroni

.pull-left[

```r
#Bonferroni
data.bonferroni &lt;- data.pvalues %&gt;% 
  mutate(bonferroni_alpha=alpha/n) %&gt;% 
  mutate(bonferrini_rechazar=ifelse(poriginal&lt;=bonferroni_alpha,1,0))
```
]

.tiny[
.pull-right[

```r
data.bonferroni
```

```
## # A tibble: 15 x 4
##    poriginal hipotesis bonferroni_alpha bonferrini_rechazar
##        &lt;dbl&gt;     &lt;dbl&gt;            &lt;dbl&gt;               &lt;dbl&gt;
##  1    0.0001         1          0.00333                   1
##  2    0.0004         2          0.00333                   1
##  3    0.0019         3          0.00333                   1
##  4    0.0095         4          0.00333                   0
##  5    0.0201         5          0.00333                   0
##  6    0.0278         6          0.00333                   0
##  7    0.0298         7          0.00333                   0
##  8    0.0344         8          0.00333                   0
##  9    0.0459         9          0.00333                   0
## 10    0.324         10          0.00333                   0
## 11    0.426         11          0.00333                   0
## 12    0.572         12          0.00333                   0
## 13    0.653         13          0.00333                   0
## 14    0.759         14          0.00333                   0
## 15    1             15          0.00333                   0
```
]
]


---

# Ejemplo: Hochberg

.pull-left[

```r
#Hochberg
data.hochberg &lt;- data.pvalues %&gt;% 
  mutate(hochberg_alpha=alpha/(n-hipotesis+1)) %&gt;% 
  mutate(hochberg_rechazar=ifelse(poriginal&lt;=hochberg_alpha,1,0))
```
]

.tiny[
.pull-right[

```r
data.hochberg
```

```
## # A tibble: 15 x 4
##    poriginal hipotesis hochberg_alpha hochberg_rechazar
##        &lt;dbl&gt;     &lt;dbl&gt;          &lt;dbl&gt;             &lt;dbl&gt;
##  1    0.0001         1        0.00333                 1
##  2    0.0004         2        0.00357                 1
##  3    0.0019         3        0.00385                 1
##  4    0.0095         4        0.00417                 0
##  5    0.0201         5        0.00455                 0
##  6    0.0278         6        0.005                   0
##  7    0.0298         7        0.00556                 0
##  8    0.0344         8        0.00625                 0
##  9    0.0459         9        0.00714                 0
## 10    0.324         10        0.00833                 0
## 11    0.426         11        0.01                    0
## 12    0.572         12        0.0125                  0
## 13    0.653         13        0.0167                  0
## 14    0.759         14        0.025                   0
## 15    1             15        0.05                    0
```
]
]

---

# Ejemplo: Benjamini &amp; Hochberg

.pull-left[

```r
#Benjamini &amp; Hochberg
data.bh &lt;- data.pvalues %&gt;% 
  mutate(bh_alpha=alpha*hipotesis/n) %&gt;% 
  mutate(bh_rechazar=ifelse(poriginal&lt;=bh_alpha,1,0))
```
]

.tiny[
.pull-right[

```r
data.bh
```

```
## # A tibble: 15 x 4
##    poriginal hipotesis bh_alpha bh_rechazar
##        &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;       &lt;dbl&gt;
##  1    0.0001         1  0.00333           1
##  2    0.0004         2  0.00667           1
##  3    0.0019         3  0.01              1
##  4    0.0095         4  0.0133            1
##  5    0.0201         5  0.0167            0
##  6    0.0278         6  0.02              0
##  7    0.0298         7  0.0233            0
##  8    0.0344         8  0.0267            0
##  9    0.0459         9  0.03              0
## 10    0.324         10  0.0333            0
## 11    0.426         11  0.0367            0
## 12    0.572         12  0.04              0
## 13    0.653         13  0.0433            0
## 14    0.759         14  0.0467            0
## 15    1             15  0.05              0
```
]
]

---

class: inverse, middle, center

# Índices

---

# Creación de `\(z\)`-scores

- Otra forma comúnmente usada de evitar el problema de las múltiples hipótesis es crear índices

- Kling, Liebmand y Katz (2007) proponen el siguiente promedio de los `\(z\)`-score para generar un solo índice

  1. Definir las familias y las variables que componen cada familia, donde `\(y_{ij}\)` es la `\(j\)`ésima variable en la familia con `\(J\)` variables
  
  1. Definir las varibles `\(y_{ij}\)` de tal forma que mayores valores se interpreten como *mejora*
  
  1. Crear `\(z_{ij}\)` como `\(z_{ij}=\frac{y_{ij}-\bar{y_j}^C}{sd(y_j)^C}\sim(0,1)\)`, es decir, estandarizar cada una de las `\(J\)` variables usando al grupo de control como referencia
  
  1. Crear `\(z_i\)`, un solo índice para cada individuo que agregue los `\(J\)` índices creados antes

- El procedimiento descrito en Banerjee et al. (2015) es bastante general, pues incluye el caso donde hay varias rondas de seguimiento y varios países
  
---

# Creación de `\(z\)`-scores

- Podemos escribir el índice descrito como

  `$$z_i=\frac{(\frac{1}{J}\sum_j z_{ij})-\bar{z}_j^C}{sd(z_j^C)}$$`

- Esta transformación tiene la ventaja de que en la siguiente regresión de efecto de tratamiento

`$$z_i=\alpha+\beta T_i + X_i'\gamma+\varepsilon_i$$`

el coeficiente `\(\beta\)` se interpreta como el efecto del tratamiento medido en desviaciones estándar con respecto a la media del grupo de control

--

- Noten que todos las variables dentro de la familia *pesan* igual

- Quizás nos gustaría tomar en cuenta la correlación entre las variables dentro del índice

---

# Índice de Anderson

- Anderson (2008) propone el siguiente índice, que puede verse como una generalización del de Kling:

`$$\bar{s}_i=\frac{1}{W_{i}}\sum_{j\in J} w_j z_{ij}$$`
- `\(w_j\)` es el peso para la variable `\(j\)` y `\(W_i=\sum_{j\in J}w_{j}\)`

- Los pesos son una función de la matriz de covarianzas entre las variables que conforman la familia

---

# Próxima sesión

- Continuaré con para afinar la estimación, ahora hablando sobre errores estándar y formas alternativas de hacer inferencia 

  - MHE, Capítulo 8
  - Ho, D. E., &amp; Imai, K. (2006). Randomization inference with natural experiments: An analysis of ballot effects in the 2003 California recall election. *Journal of the American Statistical Association*, 101(475), 888-900.
  
- Discutiremos cómo lo que hemos visto está implementado en una aplicación reciente

  - Rojas Valdes, R.I., Wydick, B., &amp; Lybbert, T.J. (2020). Can Hope Elevate Microfinance? Evidence from Oaxaca, Mexico. Forthcoming in *Oxford Economic Papers*.

---

class: center, middle

Presentación creada usando el paquete [**xaringan**](https://github.com/yihui/xaringan) en R.

El *chakra* viene de [remark.js](https://remarkjs.com), [**knitr**](http://yihui.org/knitr), y [R Markdown](https://rmarkdown.rstudio.com).

Material de clase en versión preliminar.

**No reproducir, no distribuir, no citar.**


    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="https://platform.twitter.com/widgets.js"></script>
<script src="libs/cols_macro.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9",
"navigation": {
"scroll": false
}
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
