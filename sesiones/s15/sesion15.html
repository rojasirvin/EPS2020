<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Métodos de pareamiento</title>
    <meta charset="utf-8" />
    <meta name="author" content="Irvin Rojas" />
    <script src="libs/header-attrs-2.3/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/metropolis-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="libs\cide.css" type="text/css" />
    <link rel="stylesheet" href="https:\\stackpath.bootstrapcdn.com\bootstrap\4.3.1\css\bootstrap-grid.min.css" type="text/css" />
    <link rel="stylesheet" href="https:\\use.fontawesome.com\releases\v5.7.2\css\all.css" type="text/css" />
    <link rel="stylesheet" href="https:\\cdn.rawgit.com\jpswalsh\academicons\master\css\academicons.min.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">

class: title-slide



&lt;style type="text/css"&gt;
.huge .remark-code { /*Change made here*/
  font-size: 200% !important;
}
.tiny .remark-code { /*Change made here*/
  font-size: 60% !important;
}
&lt;/style&gt;

.title[
# Sesión 15. Métodos de pareamiento
]
.subtitle[
## Evaluación de Programas Sociales
]
.author[
### Irvin Rojas &lt;br&gt; [rojasirvin.com](https://www.rojasirvin.com/) &lt;br&gt; [&lt;i class="fab fa-github"&gt;&lt;/i&gt;](https://github.com/rojasirvin) [&lt;i class="fab fa-twitter"&gt;&lt;/i&gt;](https://twitter.com/RojasIrvin) [&lt;i class="ai ai-google-scholar"&gt;&lt;/i&gt;](https://scholar.google.com/citations?user=FUwdSTMAAAAJ&amp;hl=en)
]

.affiliation[
### Centro de Investigación y Docencia Económicas &lt;br&gt; División de Economía
]

---
# Motivación
 
- Se considera la evaluación aleatoria como el *gold standard* de los métodos de evaluación
  
- Bajo una aleatorización correcta de los tratamientos, las diferencias entre los grupos de tratamiento y control son atribuibles al tratamiento
  
- Sin embargo, existen razones por las cuales es imposible llevar a cabo una asignación aleatoria
  
- ¿Nos conformamos con no poder decir nada?
    
- Podemos usar métodos no experimentales que recaen sobre diversos supuestos para hacer inferencia sobre la efectividad del tratamiento
  
---

class: inverse, middle, center

# El modelo de evaluación

---

# Resultados contrafactuales
 
- Queremos evaluar el efecto de una política, programa o intervención
  
- Tenemos `\(i=1,...,N\)` individuos
  
- Denotamos `\(Y(D_i)\)` a la variable de resultados del individuo `\(i\)` que depende del estado de tratamiento que recibió `\(D_i\)`
    
- El efecto del tratamiento para `\(i\)` es:

$$
\tau_i=Y_i(1)-Y_i(0)
$$
  
- Solo vemos a `\(i\)` en un estado de tratamiento
 
---

# Parámetros de interés

$$
ATE=E(Y(1)-Y(0))
$$

- ¿Cuál es el efecto esperado del tratamiento si tomamos un individuo al azar de la *población*?
    
$$
`\begin{aligned}
TOT&amp;=E(Y(1)-Y(0)|D=1) \\
&amp;=E(Y(1)|D=1)-E(Y(0)|D=1)
\end{aligned}`
$$
  
- El efecto del tratamiento en aquellos que participaron en este
  
- Pero la segunda parte de la definición de `\(TOT\)` no es observable
  
- ¿Qué pasa si nos fijáramos en `\((Y(0)|D=0)\)`, la variable de resultados de los no tratados?

---

# Sesgo de selección
 
- Las razones que deteriminan la asignación del tratamiento determinen también el valor de `\(Y\)`
    
$$
`\begin{aligned}
E(Y(1)|D=1)&amp;-E(Y(0)|D=1)=\\
=&amp;TOT+E(Y(0)|D=1)-E(Y(0)|D=0)
\end{aligned}`
$$

- La diferencia `\(E(Y(0)|D=1)-E(Y(0)|D=0)\)` es el **sesgo de selección**
  
- Es decir, la diferencia en resultados entre tratados y no tratados nos da el `\(TOT\)` solo si el sesgo de selección es cero
  
- Una forma de eliminar el sesgo de selección es mediante la asignación aleatoria del tratamiento
  
- Esto no siempre es posible por lo que recurrimos a supuestos para eliminar el sesgo de selección
 
---
  

# Supuestos de identificación del TOT
 
- **Supuesto 1. Inconfundibilidad**
  
$$
Y(0), Y(1) \perp  D|X
$$

  
- Dado un conjunto de variables `\(X\)`, los resultados potenciales son independientes del tratamiento
  
- `\(X\)` debe incluir todas las variables que determinan el tratamiento y los resultados potenciales
  
- **Supuesto 2: Traslape**
  
$$
0&lt; P(D=1|X) &lt; 1
$$

- `\(X\)` no predice `\(D\)` perfectamente
  
- Personas con el mismo `\(X\)` tienen probabilidad positiva de ser tratados y no tratados

---
 
# Supuestos de identificación del TOT
 
- En la literatura, **Supuesto 1** `\(+\)` **Supuesto 2** se conoce como **ignorabilidad fuerte**
  
- Heckman (1998) muestra que estás condiciones son demasiado estrictas
  
- Para identificar el `\(TOT\)` es suficiente:
    
- **Supuesto 1a. Inconfundibilidad en los controles**

$$
Y(0) \perp  D|X
$$

- **Supuesto 2a. Traslape débil**

$$
P(D=1|X) &lt; 1
$$

---

class: inverse, middle, center

# Matching exacto

---

# Matching exacto
 
- Un estimador de matching exacto consiste en  individuos tratados y no tratados para cada valor específico de las `\(X\)` y luego tomar el promedio de las diferencias con los pesos apropiados
  
- Tenemos datos observacionales de individuos que recibieron y no recibieron un tratamiento
  
- Tenemos una serie de características discretizadas en `\(X_i\)`
    
- `\(X_i\)` incluye, por ejemplo, raza, año de solicitud de ingreso al programa, escolaridad, calificación en examen de aptitud, año de nacimiento (son las características del ejemplo que vermeos más adelante)
  
- Estas características definene *celdas* y dentro de cada celda tenemos tratados y no tratados
 
---

# Efecto del tratamiento con matching exacto
 
- El TOT asumiendo inconfundibilidad:

$$
`\begin{aligned}
\delta^M=TOT&amp;=E\left\{ E(y_{1i}|X_i,D_i=1)-E(y_{0i}|X_i,D_i=0)|D_i=1\right\} \\
&amp;=E\left\{\delta_X | D_i=1\right\}
\end{aligned}`
$$

- `\(\delta_X\)` es la diferencia de ingresos promedio entre estados de tratamiento para cada valor de `\(X_i\)`
    
- Con `\(X_i\)` discreta y con una muestra disponible:

$$
\delta^M=\sum_{x} \delta_x P(X_i=x|D_i=1)
$$
---
  
# Ejemplo: veteranos de guerra en Estados Unidos

- [Angrist (1998)](https://www.jstor.org/stable/2998558), Estimating the Labor Market Impact of Voluntary Military Service Using Social Security Data on Military Applicants

- El tratamiento es haber servido en el ejercito, algo que claramente tiene autoselección

- Se trata de estimar el efecto en el ingreso

- Los autores construyen celdas de acuerdo a las características antes mencionadas

  - Raza, año de solicitud de ingreso al programa, escolaridad, calificación en examen de aptitud, año de nacimiento

---

# Ejemplo: veteranos de guerra en Estados Unidos

.pull-left[
&lt;img src="figures/ExactMatching_effects_table_a.jpg" width="100%" style="display: block; margin: auto;" /&gt;
]

.pull-right[
&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="figures/ExactMatching_effects_table_b.jpg" alt="Fuente: Angrist (1998)" width="100%" /&gt;
&lt;p class="caption"&gt;Fuente: Angrist (1998)&lt;/p&gt;
&lt;/div&gt;
]


---

# Ejemplo: veteranos de guerra en Estados Unidos

- Noten la primera segunda muestra lo que se hubiera concluido si solo se comparan diferencias de medias
    
- Antes de 1980, las diferencias eran muy pequeñas (cero en términos prácticos)
  
- En esta aplicación esta comparación llevaría a conclusiones incorrectas
  
- Además, las diferencias para no-blancos y blancos son distintas
  
- Hay un pico en los afectos alrededor de 1982
  
- En esta aplicación, los resultados por *matching* y regresión son muy parecidos hasta 1984
  
- La conclusión es que existe evidencia de efectos negativos en los ingresos por haber servido en el ejército en los blancos y efectos positivos para los individuos de otras razas

---

# Ejemplo: veteranos de guerra en Estados Unidos

.pull-left[
&lt;img src="figures/ExactMatching_effects_graph_a.jpg" width="100%" style="display: block; margin: auto;" /&gt;
]

.pull-right[
&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="figures/ExactMatching_effects_graph_b.jpg" alt="Fuente: Angrist (1998)" width="100%" /&gt;
&lt;p class="caption"&gt;Fuente: Angrist (1998)&lt;/p&gt;
&lt;/div&gt;
]

---

class: middle, inverse, center
  
# El *propensity score*

---

# Matching exacto es impráctico
 
  - En la práctica es difícil manejar problemas en espacios de múltiples dimensiones: **maldición de la dimensionalidad**
 
- El problema de la maldición de la dimensionalidad se exacerba con el tamaño limitado de las bases de datos
 
- Si `\(X\)` tuviera solo indicadores binarios, el número de posibles combinaciones sería `\(2^s\)`
   
- Por ejemplo, si solo tuviéramos `\(X_1=\{\text{hombre}, \text{mujer}\}\)`, `\(X_2=\{\text{más que preparatoria}, \text{menos que preparatoria}\}\)`, `\(X_3=\{\text{indígena}, \text{no indígena}\}\)`, tendríamos que hacer ocho comparaciones:
   
  - hombre, más que preparatoria, indígena
  - hombre, más que preparatoria, no indígena
  - ...
  - mujer, menos que preparatoria, no indígena

- Pero Si `\(X\)` incluye muchas variables, algunas tomando muchos valores, esto se vuelve imposible de realizar
  
---

# Teorema del PS (Rosenbaum y Rubin, 1983)
 
- **Corolario 1. Inconfundibilidad dado el propensity score**
 
- El **Supuesto 1** implica:
 
$$
Y(0), Y(1) \perp  D|P(X)
$$
 
donde `\(P(X)=P(D=1|X)\)` es la probabilidad de ser tratado dado un conjunto de covariables `\(X\)`, el *propensity score* o PS
  
---
  
# Estimación
 
- Podemos estimar el efecto del tratamiento:
   
$$
TOT^{PSM}=E_{P(X)|D=1} \left\( E(Y(1)|D=1, P(X))-E(Y(0)|D=0,P(X)) \right\)
$$
 
 
- El `\(TOT\)` es la diferencia en la variable de resultados de los tratados y los no tratados pesada por la distribución del PS en los tratados
  
---

# Estimación
 
- Debemos por tanto primero calcular el PS
 
- Se empatan o se hace match de unidades que fueron tratadas con unidades que no lo fueron usando el PS
 
- Se mide la diferencia en la variable de resultados entre estos grupos
 
- Se hace un promedio ponderado de las diferencias
  
---

# Implementación

1. Estimación del PS
 
2. Escoger el algoritmo de matching
 
3. Comprobar la calidad del matching
 
4. Estimar el `\(TOT\)`

---

# Especificar el modelo del PS
 
- Se usa un modelo *probit* o *logit*
 
  - **Prueba y error**.   Maximizar la tasa clasificación de tratamientos y controles usando `\(\bar{P}\)`, la proporción de tratamientos en la muestra
 
  - **Significancia estadística**.   Usar solo las variables estadísticamente significativas, comenzando con un modelo muy básico
 
  - **Validación cruzada**.   Comenzar con un modelo simple y agregar grupos de variables comparando las que reduzcan el error cuadrático promedio

- El propósito del PS es sobre todo generar balance de las variables en `\(X\)`
    
---

# Recomendaciones prácticas
 
- Las características `\(X\)` que determinan la probabilidad de tratamiento deben ser observables
 
- Las variables usadas para calcular el PS no deben haber sido afectadas por el tratamiento
 
- Idealmente usamos variables `\(X\)` pre-intervención
 
- Cuando no hay `\(X\)` pre-intervención, a veces se puede obtener el PS con variables post-intervención siempre y cuando estas no hayan sido afectadas por el tratamieto (pocas veces recomendado)
  
---

# Algoritmos de matching más populares
  
1. Vecino más cercano
 
1. Radio
 
1. Estratificación
 
1. Kernel y otros métodos no paramétricos
---

# Vecino más cercano
 
- A cada individuo del grupo tratado se le asigna uno del grupo de comparación en términos del PS
 
- Puede hacerse con remplazo o sin remplazo
 
- Puede emplearse también sobremuestreo (*oversampling*), es decir, asignar más de un individuo del grupo de comparación

  - Por ejemplo NN 5 significa que a cada individuo tratado se le asignan los cinco individuos del grupo no tratado con los PS estimados más cercanos
  
  
---

# Vecino más cercano

.pull-left[
| Tratados | `\(\hat{p}\)` |
|:---: |:---:|
| a | 0.031 |
| b | 0.042 |
| c | 0.07 |
| d | 0.11 |
| `\(\vdots\)` | `\(\vdots\)` |
]

.pull-rights[
| No tratados | `\(\hat{p}\)` |
|:---: |:---:|
| A | 0.034 |
| B | 0.068 |
| C | 0.21 |
| D | 0.40 |
| `\(\vdots\)` | `\(\vdots\)` |
] 

- Con vecino más cercano, el individuo `\(a\)` tratado estaría emparejado con el `\(A\)` no tratado

- Si el emparejamiento es con reemplazo, `\(A\)` podría ser usado otra vez

  - De hecho, con reemplazo, `\(b\)` también sería emparejado con `\(A\)`

- Pero si el emparejamiento es sin reemplazo, `\(A\)` ya no puede ser usado y a `\(b\)` se le emparejaría con `\(B\)`

--

- Cuando hacemos el pareamiento sin reemplazo, debemos tener una muestra lo suficientemente grande

- Claramente, el pareamiento sin reemplazo depende del orden en que se realice el procedimiento se realice

---

# Caliper y radio
 
- El método de vecino más cercano puede generar malos matches si el vecino más cercano está muy lejos en términos del PS
  
- El método de *caliper* consite en definir una vecindad aceptable de matching (el caliper) y elegir solo el vecino más cercano dentro del caliper
 
- Una extensión natural de este procedimiento es el método de *radio*, que consiste en definir un caliper y después hacer el match con todos los individuos en los límites del *caliper*
  
---

# Caliper

.pull-left[
| Tratados | `\(\hat{p}\)` |
|:---: |:---:|
| a | 0.031 |
| b | 0.042 |
| c | 0.07 |
| d | 0.11 |
| `\(\vdots\)` | `\(\vdots\)` |
]

.pull-rights[
| No tratados | `\(\hat{p}\)` |
|:---: |:---:|
| A | 0.034 |
| B | 0.068 |
| C | 0.21 |
| D | 0.40 |
| `\(\vdots\)` | `\(\vdots\)` |
] 

- El primer paso es fijar el caliper, por ejemplo, de 0.1

- El caliper implica buscar al vecino más cercano dentro de una vecindad de 0.1

- En este ejemplo `\(c\)` podría ser solo emparejado con `\(B\)` si `\(B\)` aún está disponible (porque no ha sido emparejado con nadie o porque aunque haya sido emparejado, el procedimiento se hace con reemplazo

---

# Caliper con sobremuestreo

.pull-left[
| Tratados | `\(\hat{p}\)` |
|:---: |:---:|
| d | 0.31 |
| e | 0.39 |
| f | 0.44 |
| g | 0.52 |
| h | 0.55 |
| i | 0.62 |
| `\(\vdots\)` | `\(\vdots\)` |
]

.pull-rights[
| No tratados | `\(\hat{p}\)` |
|:---: |:---:|
| R | 0.27 |
| S | 0.29 |
| T | 0.33 |
| U | 0.49 |
| V | 0.57 |
| W | 0.61 |
| `\(\vdots\)` | `\(\vdots\)` |
] 

- Si el caliper se realiza con sobremuestreo, con un caliper de 0.10 y 2 vecinos a `\(g\)` se le asignarían `\(U\)` y `\(V\)` (si estuvieran disponibles)

- Es decir, dentro del caliper, los dos individuos con el PS más cercano

---

# Radio

.pull-left[
| Tratados | `\(\hat{p}\)` |
|:---: |:---:|
| d | 0.31 |
| e | 0.39 |
| f | 0.44 |
| g | 0.52 |
| h | 0.55 |
| i | 0.62 |
| `\(\vdots\)` | `\(\vdots\)` |
]

.pull-rights[
| No tratados | `\(\hat{p}\)` |
|:---: |:---:|
| R | 0.27 |
| S | 0.29 |
| T | 0.33 |
| U | 0.49 |
| V | 0.57 |
| W | 0.61 |
| `\(\vdots\)` | `\(\vdots\)` |
] 

- Pero si ahora implementamos radio con un caliper de 0.10, a `\(g\)` se le asignarían `\(U\)`, `\(V\)` y `\(W\)` (si estuvieran disponibles)

- Es decir, todos los individuos dentro del caliper


---

# Estratificación
 
- Partir la región de soporte común en bloques de acuerdo al PS
 
- Estimar el efecto de tratamiento dentro de cada bloque
 
- No hay una regla sobre cuántos estratos usar. Se aconsajan generalmente cinco
 
- Un procedimiento para seleccionar el número de estratos y corroborar el balance es:

  1. Partir el rango de soporte común en cinco bloques iguales
 
  1. Mostrar que el PS está balanceado en cada bloque. Si no, partir dicho bloque
 
  1. Una vez que el PS está balanceado, repetir el procedimiento pero para cada variable en `\(X\)`
   
  1. Si no se pueden balancer las variables `\(X\)`, reestimar el PS con una nueva especificación

  
---

# Kernel y métodos no paramétricos
 
- Los métodos anteriores escogen solo unas cuantas unidades del grupo de comparación 
 
- Podemos escoger usar muchas o incluso todas las observaciones del grupo de comparación y pesarlas apropiadamente
 
- Se reduce la varianza pues usamos más información pero se sacrifica precisión pues se usan observaciones potencialmente muy distantes
 
- Se le otorga más peso a las observaciones más cercanas y menos a las más distantes
  
---

# Kernel

.pull-left[
| Tratados | `\(\hat{p}\)` |
|:---: |:---:|
| d | 0.31 |
| e | 0.39 |
| f | 0.44 |
| g | 0.52 |
| h | 0.55 |
| i | 0.62 |
]

.pull-rights[
| No tratados | `\(\hat{p}\)` |
|:---: |:---:|
| R | 0.27 |
| S | 0.29 |
| T | 0.33 |
| U | 0.49 |
| V | 0.57 |
| W | 0.61 |
] 

- Supongamos que estos son todos nuestros datos

- Con un emparejamiento por kernel, a `\(a\)` lo compararemos con todos los individuos, desde `\(R\)` hasta `\(W\)`

- La función kernel le dará más peso a `\(R\)`, un poco menos a `\(S\)` y así hasta darle muy poco o casi nada de peso a `\(W\)`

---

# ¿Qué método usar?
 
- No hay un método claramente superior a todos los demás
 
- Más aún, el desempeño de cada método depende de cada aplicación
 
- La ruta más seguida es usar varios algoritmos y mostrar la robustez de los resultados a esta elección
  
---

# Comprobar empíricamente los supuestos
 
- El parámetro `\(TOT\)` solo se calcula sobre la región de sporte común por lo que se debe verificar el traslape del PS calculado para los tratados y no tratados
 
- Otro de los teoremas de Rosenbaum y Rubin (1983) implica que

$$
X \perp  D|P(X)
$$
 
es decir, que al controlar por el PS, las variables `\(X\)` no deben proveer información sobre `\(D\)`
   
- Se recomienda también hacer una prueba de estratificación

  1. Dividir el rango del soporte común en bloques 
 
  1. Hacer una prueba de medias del PS entre grupos dentro de cada bloque
 
  1. Hacer una prueba de medias de cada variable en `\(X_i\)`  entre grupos dentro de cada bloque

---

# Ilustración del soporte común

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="figures/Gertler_PSOverlap.png" alt="Fuente: Gertler et al. (2017)" width="70%" /&gt;
&lt;p class="caption"&gt;Fuente: Gertler et al. (2017)&lt;/p&gt;
&lt;/div&gt;
---

# Definición del `\(TOT^M\)`
 
- Sea `\(i\)` un individuo tratado con características `\(x\)`
   
- `\(A_i\)` es el conjunto de individuos de comparación para el individuo `\(i\)`:
 
`$$A_i(x)=\left\{j|x_j \in c(x_i) \right\}$$`
 
 
donde `\(c(x_i)\)` es la vecindad de las características de `\(x_i\)`
   
- `\(N_T\)` y `\(N_C\)` es el número de individuos tratados y no tratados
 
- `\(w(i,j)\)` es el peso al caso `\(j\)`-ésimo en la comparación para el individuo `\(i\)`, con `\(\sum_j w(i,j)=1\)`
   
- El `\(TOT\)` es:
   
`$$TOT^M=\frac{1}{N_T}\sum_{i\in{D=1}}\left(y_{1i}-\sum_j w(i,j) y_{0j}\right)$$`
 
  
---

# Distintos estimadores de matching

1. Vecino más cercano:
    `$$A_i(p(x))=\left\{p_j | \min_j || p_i - p_j || \right\}$$`
1. Radio
     `$$A_i(p(x))=\left\{p_j |  || p_i - p_j || &lt;r \right\}$$`

1. Estratificación
     `$$TOT^M_{E}=\sum_{b=1}^{B}TOT_b \left(\frac{\sum_{i\in I(b)} D_i}{\sum D_i}\right)$$`
 
1. Kernel
    `$$w(i,j)=\frac{K(p(x_i)-p(x_j))}{\sum_{j=1}^{N_{c_i}}K(p(x_i)-p(x_j))}$$`
 
---

# Varianza del estimador `\(TOT^M\)`
 
- Nos interesa conocer la precisión de nuestro estimador
 
- Debemos tomar en cuenta que el PS no es observado sino estimado
 
- Se recomienda usar la fórmula para la varianza de Abadie e Imbens (2006)
 
- Esta fórmula se usa con el comando *teffects* en R
 
- Estos autores de hecho recomiendan no usar bootstrap

---

class: inverse, middel, center

# ¿Qué tanto podemos confiar en PSM?


---

# Ventajas y desventajas del PSM
 
- Ventajas

  - Se pone atención al proceso de selección
  - Al imponer la condición de soporte común las unidades comparadas son muy parecidas
  - Es un método versátil que puede extenderse para analizar heterogeneidad o múltiples tratamientos

- Desventajas

  - Es necesaria una gran cantidad de datos para asegurar que se comparar unidades similares
  - Los supuestos que se hacen son muy fuertes pero no pueden verificarse empíricamente
  		 
---

# Métodos no experimentales
 
- ¿Qué tanto podemos confiar en las conclusiones de los métodos no experimentales?

- Hay una serie de decisiones que hacen los resultados sensibles
  - Base de datos a emplear
  
  - Especificación del PS
  
  - Elección del método de matching
	 
- No sabemos cuál es el efecto *verdadero*

... o quizás sí
 
---

# Métodos no experimentales
 
 - LaLonde (1986) realizó un estudio para analizar el desempeño de métodos no experimentales
 
 - El Programa Nacional de Empleo (NSW) en Estados Unidos fue un programa que acercaba a fuentes de empleo a individuos desaventajados
 
 - Fue lanzado en 1975 y se asignó de forma aleatoria
 
 - Se recolectó información de individuos tratados y no tratados en una línea base y en encuestas de seguimiento
 
 - El efeto de tratamiento *verdadero* se puede obtener al comparar los ingresos de los individuos tratados y los no tratados
 
 - Pero, si hubiéramos tenido que usar métodos no experimentales, ¿habríamos obtenido lo mismo?
 
---

# Los resultados de LaLonde (1986)

- El efecto estimado usando la variación experimental es $886 USD

  - En su artículo original, LaLonde (1986) muestra que métodos de regresión y de selección de Heckman no sirven para aproximar el resultado experimental
  
--
 
- Dehejia y Wahba (1999) retoman el estudio de LaLonde para tratar de aproximar el resultado experimental usando PSM

- Los grupos de comparación son muestras de dos encuestas: el PSID y la CPS

- Es importante notar que estas dos encuestas tenían muy individuos muy diferentes a los de la base de NSW en términos de ingreso

---

# Los resultados de LaLonde (1986)

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="figures/DehejiaWahba_balance.png" alt="Fuente: Dehejia &amp;amp; Wahba (1999)" width="65%" /&gt;
&lt;p class="caption"&gt;Fuente: Dehejia &amp; Wahba (1999)&lt;/p&gt;
&lt;/div&gt;

---

# Resultados de Dehejia y Wahba (1999)
 
- Dehejia y Wahba usan una submuestra de los datos de LaLonde que les permita observar ingresos pre-intervención

- Por tanto, se estudia el efecto del programa sobre los ingresos de 1978

- Es de notar que esto hace ya a la muestra de Deheija y Wahba diferente a la de LaLonde en términos del efecto insesgado, ahora de $1,794 USD
	 
	 
---

# Balance del PS

- Recordemos que el `\(TOT\)` solo se puede calcular si hay suficiente traslape en el PS

- Noten que el traslape no es el ideal

- En esta aplicación la ventaja es que conocemos el estimador insesgado

- El PS se estima incluyendo: edad (y su cuadrado), educación (y su cuadrado), indicador de casado, indicador de estudios superiores, indicador de negro, indicador de hispano, ingreso de 1974 (y su cuadrado) e ingresos de 1975 (y su cuadrado)

	 
---

# Balance del PS


&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="figures/DehejiaWahba_PS.png" alt="Fuente: Dehejia &amp;amp; Wahba (1999)" width="68%" /&gt;
&lt;p class="caption"&gt;Fuente: Dehejia &amp; Wahba (1999)&lt;/p&gt;
&lt;/div&gt;
---

# Resultados principales
 
- La columna (1) resulta de tomar la diferencia entre tratados en la encuesta de NSW y los individuos en las muestras del PSID y la CPS

- Noten que esto llevaría a conclusiones muy diferentes respecto al efecto del programa, comparado con el efecto insesgado de $1,794 USD

- Los resultados de PSM por estratificación están en la columna (4) y por vecino más cercano en la (7)

- Hay resultados muy cercanos a la versión experimental
 
---

# Resultados principales

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="figures/DehejiaWahba_results.png" alt="Fuente: Dehejia &amp;amp; Wahba (1999)" width="80%" /&gt;
&lt;p class="caption"&gt;Fuente: Dehejia &amp; Wahba (1999)&lt;/p&gt;
&lt;/div&gt;

---

# Sensibilidad
 
- Noten que los resultados cambian de forma sensible al usar algunas muestras

- Por ejemplo, usando PSID-3, el estimador por estratificación es $2,321 USD (19% superior más que el estimador insesgado)

- El efecto estimado usando vecino más cercano y CPS-3 es solo $587 USD (%70 por ciento menor)

- Los resultados de Dehejia y Wahba fueron tomados inicialmente como la validación del método de PSM

- Más aún, al hacer una especificación sin incluir los ingresos de 1974 en `\(X\)` para estimar el PS, los resultados se vuelven incluso negativos
 

---

# Sensibilidad

&lt;div class="figure" style="text-align: center"&gt;
&lt;img src="figures/DehejiaWahba_sensitivity.png" alt="Fuente: Dehejia &amp;amp; Wahba (1999)" width="55%" /&gt;
&lt;p class="caption"&gt;Fuente: Dehejia &amp; Wahba (1999)&lt;/p&gt;
&lt;/div&gt;

---

# Conclusión

- Las técnicas de PSM dependen de varios supuestos téoricos fuertes

- La implementación implica que las variables en `\(X\)` son aquellas que permiten hacer los supuestos de inconfundibilidad dado el PS

- En la estimación del PS se toma la decisión sobre la forma funcional

- Los efectos de tratamiento pueden ser distintos entre diferentes algoritmos de emparejamiento y la especificación del PS

--

- Pero muchas veces es todo lo que tenemos a la mano

- Hay que hacer análisis de sensibilidad a las distintas decisiones

- Presentar resultados transparentes

---

# Próxima sesión

- Veremos ejemplos típicos de PSM

 + Becerril, J., &amp; Abdulai, A. (2010). The impact of improved maize varieties on poverty in Mexico: a propensity score-matching approach. *World development*, 38(7), 1024-1035.

  + Espinosa, V., &amp; Rubin, D. B. (2015). Did the military interventions in the Mexican drug war increase violence?. *The American Statistician*, 69(1), 17-27

  
---

class: center, middle

Presentación creada usando el paquete [**xaringan**](https://github.com/yihui/xaringan) en R.

El *chakra* viene de [remark.js](https://remarkjs.com), [**knitr**](http://yihui.org/knitr), y [R Markdown](https://rmarkdown.rstudio.com).

Material de clase en versión preliminar.

**No reproducir, no distribuir, no citar.**


    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="https://platform.twitter.com/widgets.js"></script>
<script src="libs/cols_macro.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9",
"navigation": {
"scroll": false
}
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
